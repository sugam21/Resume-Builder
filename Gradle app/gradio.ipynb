{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import gradio\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from gensim.models import KeyedVectors # For loading saved gensim model\n",
    "from simpletransformers.question_answering import QuestionAnsweringModel # This is for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_ = \"/home/sugam/Work/10-19 NLP/12 Projects/Resume Builder/Output/\"\n",
    "data_dir =  \"/home/sugam/Work/10-19 NLP/12 Projects/Resume Builder/data/Processed/\"\n",
    "\n",
    "model = model_dir_ + \"bert/\"\n",
    "context_data = data_dir + \"context_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat Interface\n",
    "- Question -> given as input to the chatbot\n",
    "- Preprocessing Pipeline to process question\n",
    "- Embedding data to match cosine similarity\n",
    "- Original context data to get the context\n",
    "- Model to predict the value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowerCasing(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"Takes the string and converts into lower casing\"\"\"\n",
    "\n",
    "    def fit(self,text,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,text):\n",
    "        return text.lower()\n",
    "\n",
    "\n",
    "class RemovePunctuation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Takes the string and removes punctuation\"\"\"\n",
    "    \n",
    "    def fit(self,text,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,text):\n",
    "        exclude = '!\"#$%&\\'()*+./:;<=>?@[\\\\]^`{|}~'\n",
    "        text = text.translate(str.maketrans(\"\",\"\",exclude))\n",
    "        text = re.sub(\",\",\" \",text)\n",
    "        text = re.sub(r\"\\(\",\" \",text)\n",
    "        text = re.sub(r\"\\)\",\" \",text)\n",
    "\n",
    "        return text\n",
    "\n",
    "\n",
    "class RemoveAccent(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"Takes string and removes accent words\"\"\"\n",
    "    \n",
    "    def fit(self,text,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,text):\n",
    "        accent_letters = 'éàáñüãèìöäøõîûçôšâ'\n",
    "        text = text.translate(str.maketrans(\"\",\"\",accent_letters))\n",
    "\n",
    "        return text\n",
    "\n",
    "\n",
    "class RemoveStopWords(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"Takes the string and remove the stopwords\"\"\"\n",
    "    \n",
    "    def fit(self,text,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,text):\n",
    "        new_text = []\n",
    "        for words in text.split():\n",
    "            if words not in stopwords.words(\"english\"):\n",
    "                new_text.append(words)\n",
    "            else:\n",
    "                new_text.append(\"\")\n",
    "        text = \" \".join(new_text)\n",
    "\n",
    "        return text\n",
    "    \n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"lower\",LowerCasing()),\n",
    "    (\"remove punctuation\",RemovePunctuation()),\n",
    "    (\"remove accent\",RemoveAccent()),\n",
    "    (\"remove stopwords\",RemoveStopWords())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORD2VEC CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec():\n",
    "  \"\"\"\n",
    "  The class is responsible for importing the saved gensim word2vec 200 dim vector and use it to encode the question\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,path):\n",
    "      self.wv = KeyedVectors.load(path)\n",
    "\n",
    "  def sent_vec(self,sent):\n",
    "    \"\"\"\n",
    "    Creates a vector from sentence \n",
    "    \"\"\"\n",
    "    vector_size = self.wv.vector_size\n",
    "    wv_res = np.zeros(vector_size)\n",
    "    ctr = 1\n",
    "    for w in sent:\n",
    "      if w in self.wv:\n",
    "        ctr+=1\n",
    "        wv_res += self.wv[w]\n",
    "    wv_res = wv_res/ctr\n",
    "    return wv_res\n",
    "\n",
    "  \n",
    "word_2_vec_model_dir = model_dir_+\"word2vec_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData():\n",
    "    \n",
    "\n",
    "    def __init__(self,embedding_path = \"\", context_path = \"\"):\n",
    "        self.embedding_path = embedding_path\n",
    "        self.context_path = context_path\n",
    "        \n",
    "    def load_context_embeddings(self):\n",
    "        ####### This will load premade embeddings\n",
    "        with open(self.embedding_path, \"rb\") as file:\n",
    "            vec = pickle.load(file)\n",
    "        \n",
    "        ### Convert into dataframe\n",
    "        vec = pd.DataFrame(vec)\n",
    "        \n",
    "        return vec\n",
    "    \n",
    "    def load_context_data(self):\n",
    "        #### This will load the original data for context\n",
    "        og_context = pd.read_csv(self.context_path)\n",
    "        return og_context\n",
    "        \n",
    "\n",
    "\n",
    "embedding_path = data_dir +\"word2vec_encoding.pkl\"\n",
    "context_path =  data_dir+\"context_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cosine_similarity(vec, question_vector):\n",
    "    \"\"\"\n",
    "    Takes the embedding dataframe of the context and the embedding of the question\n",
    "    Finds the cosine similarity between two\n",
    "    Gives the index whose cosine similarity is maximum\n",
    "    \"\"\"\n",
    "    vec[\"cosine_similarity\"] = vec[\"context\"].apply(lambda x: 1 - cosine(x,question_vector)) # Applies the cosine similarity and store in a new column\n",
    "    index_max_similarity = vec[\"cosine_similarity\"].argmax() # Finds the index with maximum cosine similarity\n",
    "\n",
    "    return index_max_similarity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(context_sentence,question):\n",
    "    to_predict =  [\n",
    "    {\n",
    "        \"context\": context_sentence,\n",
    "        \"qas\": [\n",
    "            {\n",
    "                \"question\": question,\n",
    "                \"id\": \"0\",\n",
    "            }\n",
    "        ],\n",
    "    }]\n",
    "\n",
    "    return to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.model = QuestionAnsweringModel(\"bert\",model+\"/best_model/\",use_cuda=False)\n",
    "    \n",
    "    def predict(self,to_predict):\n",
    "        predictions, raw_input = self.model.predict(to_predict)\n",
    "        return predictions[0][\"answer\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "Running on public URL: https://c897dbc64552de907c.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c897dbc64552de907c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 266.54it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 154.83it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 24528.09it/s]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gradio as gr\n",
    "from typing import List\n",
    "import time\n",
    "\n",
    "def random_response(message: str, history: List):\n",
    "    \"\"\"\n",
    "    The function handles whatever is to be shown in chatbot\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    message (str) - representing the user's input.\n",
    "    history (a list of list) representing the conversations up until that point. Each inner list consists of two str representing a pair: [user input, bot response].\n",
    "    \n",
    "    Returns:\n",
    "    Output to be shown\n",
    "    \n",
    "    \"\"\"\n",
    "    processed_question = pipe.fit_transform(message)  # Preprocesses the question\n",
    "    question_vector = Word2Vec(word_2_vec_model_dir).sent_vec(processed_question) # Create embedding of question\n",
    "    ld = LoadData(embedding_path=embedding_path,context_path=context_path) # Loading the pre-made context embeddings and context data\n",
    "    vec = ld.load_context_embeddings()\n",
    "    context_data = ld.load_context_data()\n",
    "    index_max_similarity = find_cosine_similarity(vec,question_vector) # Find the index of maximum cosine similarity\n",
    "\n",
    "    # Fetching the context from the original context data\n",
    "    context = context_data.iloc[index_max_similarity,0] # This will have context of the question stored to it\n",
    "    \n",
    "    to_predict = format_data(context, message) # Formatting the original question and context. Not using the processed question because the model is not trained on \n",
    "    # processed questions\n",
    "    \n",
    "    answer = Model().predict(to_predict)\n",
    "    \n",
    "    for i in range(len(answer)):\n",
    "        time.sleep(0.1)\n",
    "        yield \"The answer is->\" + answer[:i+1]\n",
    "    \n",
    "    return answer\n",
    "\n",
    "demo = gr.ChatInterface(random_response,\n",
    "                        chatbot=gr.Chatbot(height=300),\n",
    "                        textbox=gr.Textbox(placeholder=\"Ask me a yes or no question\", container=False, scale=7),\n",
    "                        title=\"ResuBot\",\n",
    "                        description=\"Ask me any job related questions\",\n",
    "                        theme=\"soft\",\n",
    "                        examples=[\"Hello\", \"Am I cool?\", \"Are tomatoes vegetables?\"],\n",
    "                        cache_examples=False,\n",
    "                        retry_btn=\"Retry\",\n",
    "                        undo_btn=\"Delete Previous\",\n",
    "                        clear_btn=\"Clear\").queue().launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
