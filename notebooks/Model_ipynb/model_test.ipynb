{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory for top level folder\n",
    "model_dir_ = \"/home/sugam/Work/10-19 NLP/12 Projects/Resume Builder/Output/\"\n",
    "data_dir =  \"/home/sugam/Work/10-19 NLP/12 Projects/Resume Builder/data/Processed/\"\n",
    "\n",
    "model = model_dir_ + \"bert/\"\n",
    "test_data = data_dir + \"test_json.json\"\n",
    "context_data = data_dir + \"context_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JT_Walkin Data Entry Operator (night Shift),CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JT_Work Based Onhome Based Part Time,CO_find l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JT_Pl,sql Developer - SQL,CO_Softtech Career I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JT_Manager,ad,partner - Indirect Tax - CA,CO_O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JT_JAVA Technical Lead (6-8 yrs) -,CO_Spire Te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context\n",
       "0  JT_Walkin Data Entry Operator (night Shift),CO...\n",
       "1  JT_Work Based Onhome Based Part Time,CO_find l...\n",
       "2  JT_Pl,sql Developer - SQL,CO_Softtech Career I...\n",
       "3  JT_Manager,ad,partner - Indirect Tax - CA,CO_O...\n",
       "4  JT_JAVA Technical Lead (6-8 yrs) -,CO_Spire Te..."
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = pd.read_csv(context_data)\n",
    "context.rename(columns={\"0\":\"context\"},inplace=True)\n",
    "context.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LowerCasing(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"Takes the string and converts into lower casing\"\"\"\n",
    "\n",
    "    def fit(self,text,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,text):\n",
    "        return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemovePunctuation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Takes the string and removes punctuation\"\"\"\n",
    "    \n",
    "    def fit(self,text,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,text):\n",
    "        exclude = '!\"#$%&\\'()*+./:;<=>?@[\\\\]^`{|}~'\n",
    "        text = text.translate(str.maketrans(\"\",\"\",exclude))\n",
    "        text = re.sub(\",\",\" \",text)\n",
    "        text = re.sub(r\"\\(\",\" \",text)\n",
    "        text = re.sub(r\"\\)\",\" \",text)\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveAccent(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"Takes string and removes accent words\"\"\"\n",
    "    \n",
    "    def fit(self,text,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,text):\n",
    "        accent_letters = 'éàáñüãèìöäøõîûçôšâ'\n",
    "        text = text.translate(str.maketrans(\"\",\"\",accent_letters))\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveStopWords(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"Takes the string and remove the stopwords\"\"\"\n",
    "    \n",
    "    def fit(self,text,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,text):\n",
    "        new_text = []\n",
    "        for words in text.split():\n",
    "            if words not in stopwords.words(\"english\"):\n",
    "                new_text.append(words)\n",
    "            else:\n",
    "                new_text.append(\"\")\n",
    "        text = \" \".join(new_text)\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"lower\",LowerCasing()),\n",
    "    (\"remove punctuation\",RemovePunctuation()),\n",
    "    (\"remove accent\",RemoveAccent()),\n",
    "    (\"remove stopwords\",RemoveStopWords())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;lower&#x27;, LowerCasing()),\n",
       "                (&#x27;remove punctuation&#x27;, RemovePunctuation()),\n",
       "                (&#x27;remove accent&#x27;, RemoveAccent()),\n",
       "                (&#x27;remove stopwords&#x27;, RemoveStopWords())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;lower&#x27;, LowerCasing()),\n",
       "                (&#x27;remove punctuation&#x27;, RemovePunctuation()),\n",
       "                (&#x27;remove accent&#x27;, RemoveAccent()),\n",
       "                (&#x27;remove stopwords&#x27;, RemoveStopWords())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LowerCasing</label><div class=\"sk-toggleable__content\"><pre>LowerCasing()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemovePunctuation</label><div class=\"sk-toggleable__content\"><pre>RemovePunctuation()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemoveAccent</label><div class=\"sk-toggleable__content\"><pre>RemoveAccent()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemoveStopWords</label><div class=\"sk-toggleable__content\"><pre>RemoveStopWords()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('lower', LowerCasing()),\n",
       "                ('remove punctuation', RemovePunctuation()),\n",
       "                ('remove accent', RemoveAccent()),\n",
       "                ('remove stopwords', RemoveStopWords())])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "context[\"context\"] = context[\"context\"].map(lambda x: pipe.fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lower_casing(text):\n",
    "#     return text.lower()\n",
    "\n",
    "# def remove_punctuation(text):\n",
    "#     exclude = '!\"#$%&\\'()*+./:;<=>?@[\\\\]^`{|}~'\n",
    "#     text = text.translate(str.maketrans(\"\",\"\",exclude))\n",
    "#     text = re.sub(\",\",\" \",text)\n",
    "#     text = re.sub(r\"\\(\",\" \",text)\n",
    "#     text = re.sub(r\"\\)\",\" \",text)\n",
    "\n",
    "#     return text\n",
    "\n",
    "\n",
    "# def remove_accent_letters(text):\n",
    "#     accent_letters = 'éàáñüãèìöäøõîûçôšâ'\n",
    "#     text = text.translate(str.maketrans(\"\",\"\",accent_letters))\n",
    "\n",
    "#     return text\n",
    "\n",
    "# def remove_stopwords(text):\n",
    "#     new_text = []\n",
    "#     for words in text.split():\n",
    "#         if words not in stopwords.words(\"english\"):\n",
    "#             new_text.append(words)\n",
    "#         else:\n",
    "#             new_text.append(\"\")\n",
    "#     text = \" \".join(new_text)\n",
    "\n",
    "#     return text\n",
    "\n",
    "\n",
    "# context[\"context\"]= context[\"context\"].map(lower_casing)\n",
    "# context[\"context\"]= context[\"context\"].map(remove_punctuation)\n",
    "# context[\"context\"]= context[\"context\"].map(remove_accent_letters)\n",
    "# context[\"context\"]= context[\"context\"].map(remove_stopwords)\n",
    "# context.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Saving the processed context data and deleting the context variable\n",
    "context.to_csv(data_dir+\"context_processed.csv\",index=False)\n",
    "del context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = pd.read_csv(data_dir+\"context_processed.csv\")\n",
    "context_series = context[\"context\"].copy()\n",
    "del context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDF(BaseEstimator,TransformerMixin):\n",
    "    def fit(self,text,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,text):\n",
    "        # Create a TF-IDF vectorizer \n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "        # Fit and transform the context data\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(context_series)\n",
    "        tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "        return tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_pipe = Pipeline([\n",
    "    (\"tfidf\",TFIDF())\n",
    "])\n",
    "tfidf_df = coding_pipe.fit_transform(context_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.to_pickle(data_dir+\"tf-idf.pkl\")\n",
    "del tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00000</th>\n",
       "      <th>0008</th>\n",
       "      <th>000i</th>\n",
       "      <th>002</th>\n",
       "      <th>0021</th>\n",
       "      <th>003</th>\n",
       "      <th>004</th>\n",
       "      <th>0073</th>\n",
       "      <th>...</th>\n",
       "      <th>zos</th>\n",
       "      <th>zs4</th>\n",
       "      <th>zsm</th>\n",
       "      <th>zuha</th>\n",
       "      <th>zuti</th>\n",
       "      <th>zycus</th>\n",
       "      <th>zydus</th>\n",
       "      <th>½cke</th>\n",
       "      <th>½ï</th>\n",
       "      <th>ïƒ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30438 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00       000  00000  0008  000i  002  0021  003  004  0073  ...  zos  zs4  \\\n",
       "0  0.0  0.168303    0.0   0.0   0.0  0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "1  0.0  0.148077    0.0   0.0   0.0  0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "2  0.0  0.000000    0.0   0.0   0.0  0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "3  0.0  0.000000    0.0   0.0   0.0  0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "4  0.0  0.000000    0.0   0.0   0.0  0.0   0.0  0.0  0.0   0.0  ...  0.0  0.0   \n",
       "\n",
       "   zsm  zuha  zuti  zycus  zydus  ½cke   ½ï   ïƒ  \n",
       "0  0.0   0.0   0.0    0.0    0.0   0.0  0.0  0.0  \n",
       "1  0.0   0.0   0.0    0.0    0.0   0.0  0.0  0.0  \n",
       "2  0.0   0.0   0.0    0.0    0.0   0.0  0.0  0.0  \n",
       "3  0.0   0.0   0.0    0.0    0.0   0.0  0.0  0.0  \n",
       "4  0.0   0.0   0.0    0.0    0.0   0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 30438 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.read_pickle(data_dir+\"tf-idf.pkl\")\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is job provided by Lok Bharti Skilling Solution Pvt Ltd company?\"\n",
    "question_vector = tfidf_vectorizer.transform([question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sugam/Work/10-19 NLP/12 Projects/Resume Builder/notebooks/Model_ipynb/model_test.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sugam/Work/10-19%20NLP/12%20Projects/Resume%20Builder/notebooks/Model_ipynb/model_test.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m question_vector\n",
      "\u001b[0;31mNameError\u001b[0m: name 'question_vector' is not defined"
     ]
    }
   ],
   "source": [
    "question_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between the question and context data\n",
    "cosine_similarities = linear_kernel(question_vector, tfidf_matrix).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0135628 , 0.        , 0.01349063, ..., 0.        , 0.        ,\n",
       "       0.02319114])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the context with the highest similarity\n",
    "closest_context_index = cosine_similarities.argmax()\n",
    "\n",
    "# Get the closest context\n",
    "closest_context = context_series[closest_context_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sugam/miniconda3/envs/simple_transformer/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import gradio as gr\n",
    "\n",
    "def random_response(message, history):\n",
    "    return random.choice([\"Yes\", \"No\"])\n",
    "\n",
    "demo = gr.ChatInterface(random_response)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
